\begin{abstract}
    This report investigates the time complexity of the Shellsort algorithm , based on both empirical measurements and formal analysis, with a particular focus on key arrangements that lead to worst-case behavior.

    Using a classic increment sequence of the form $h_t = \lfloor \frac{n}{2^t} \rfloor$, we analyze the number of element comparisons and swaps during the sorting process.
    Depending on the choice of increment sequence, average-case complexity ranges between $O(n \log n)$ and $O(n^{1.5})$\footnote{
     see \cite[262]{SW11}
    }, while worst-case scenarios can yield a theoretical upper bound of $O(n^2)$.

    Our findings emphasize that strong empirical evidence - based on large-scale tests with randomly generated inputs - is not sufficient to formally establish upper bounds.
    Instead, pathological input sequences can trigger significantly worse behavior, highlighting the importance of rigorous theoretical analysis as a complement to empirical methods (\cite[260]{SW11}).
\end{abstract}