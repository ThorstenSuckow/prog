\section{Heapsort}

\subsection{Eigenschaften}
\begin{itemize}
    \item nicht stabil
    \item in place
    \item optimal
\end{itemize}

\subsection{Methode}
Die Eingabefolge wird in einen \textbt{Max-Heap} umgewandelt.\\
Da in einem Max-Heap immer der größte Schlüssel am Anfang der Folge steht, wird der Schlüssel mit dem letzten Element der Folge ausgetauscht und die Heap-Größe um $1$ verkleinert.\\
Das an Position $1$ stehende Element wird nun über ein \textbf{top-down reheapify} in dem Heap an seine eigentliche Position gebracht, damit die Heap-Bedingungen hergestellt sind und das größte Element wieder an Position $1$ steht.\\
Das wird so lange wiederholt, bis der Heap nur noch aus einem Element besteht, dann ist die resultierende Folge sortiert.\\

\noindent
Analog läßt sich das Verfahren auf einen \textbf{Min-Heap} anwenden, bei der der kleinste Schlüssel immer am Anfang der Folge steht: Die Heap-Bedingungen sind hier, dass die Schlüssel der direkten Nachfolger eines Knotens größer oder gleich als der Schlüssel des Knotens selber sind.

\noindent
Eine Vorsortierung der Daten ändert nichts an der Laufzeit von Heapsort (vgl.~\cite[112]{OW17b}). Heapsort ist also \textit{nicht} natürlich\footnote{
ebenda verweisen \textit{Ottmann und Widmayer} auf \textbf{Smoothsort}, eine Variante von Heapsort, die auf vorsortierten Daten schneller arbeitet und $O(n)$ erreichen kann
}.

\subsection{Laufzeit}
\begin{itemize}
    \item \textbf{Aufbau des Heaps}: $O(n)$
    \item \textbf{sink}: $n$ Aufrufe, jeweils $O(log\ n)$
    \item \textbf{worst-case}: $O(n\ log\ n)$
    \item \textbf{average-case}: $O(n\ log\ n)$
    \item \textbf{best-case}: $O(n\ log\ n)$
\end{itemize}
